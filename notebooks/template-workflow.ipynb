{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU openai marvin\n",
    "%pip install -qU \"psycopg[binary]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Code**] Simple state machine parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because the outline structure of most legal codes is so simple, it's feasible to implement a parser using a hand-coded\n",
    "state machine that shifts between states according to the level of the outline. This may be a simpler approach than\n",
    "specifying a BNF-style grammar for Lark or a similar parser generator, because in some cases outlines skip levels, which\n",
    "would complicate the formal grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "#from typing import List, Dict\n",
    "from dataclasses import dataclass, field\n",
    "import re\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Level(Enum):\n",
    "    H0 = 0 # top level (initial state)\n",
    "    H1 = 1\n",
    "    H2 = 2\n",
    "    H3 = 3\n",
    "\n",
    "@dataclass\n",
    "class HeadingPattern:\n",
    "    level: Level\n",
    "    regex: str\n",
    "    multi_line: bool # whether the heading spans multiple lines\n",
    "\n",
    "@dataclass\n",
    "class Heading:\n",
    "    level: Level\n",
    "    # heading_type: str # e.g. \"section\", \"subsection\", \"article\", \"chapter\"\n",
    "    enumeration: str # number or letter (e.g. \"1\", \"a\", \"i\", \"A\", \"XVII\")\n",
    "    heading_text: str\n",
    "\n",
    "@dataclass\n",
    "class Segment:\n",
    "    level: Level\n",
    "    headings: dict[Level, Heading|None] = field(default_factory=dict)\n",
    "    body: list[str] = field(default_factory=list) # list of paragraphs\n",
    "\n",
    "## For our purposes, a document is just a list of segments -- the structure is\n",
    "## implicit in the headings, which will be uploaded to a relational database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paragraph(paragraph: str) -> tuple[str, str]:\n",
    "    \"\"\"\"Split a paragraph into its first line and the rest of the paragraph.\"\"\"\n",
    "    lines = paragraph.split('\\n', 1)\n",
    "    if len(lines) == 0:\n",
    "        return '', ''\n",
    "    first_line = lines[0]\n",
    "    rest_of_paragraph = lines[1] if len(lines) > 1 else ''\n",
    "    return first_line, rest_of_paragraph\n",
    "\n",
    "assert split_paragraph(\"\") == (\"\", \"\")\n",
    "assert split_paragraph(\"This is a\\nparagraph.\\n\") == (\"This is a\", \"paragraph.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_heading(paragraph: str, patterns: dict[Level, HeadingPattern]) -> Heading | None:\n",
    "    \"\"\"For each patern in `patterns`, check if the paragraph matches (e.g., pattern r'^Chapter [IVXLC]+'\n",
    "    matches 'Chapter VII'). If a match is found, return a Heading object. Otherwise, return None.\"\"\"\n",
    "    \n",
    "    paragraph = paragraph.strip()\n",
    "\n",
    "    for level, pattern in patterns.items():\n",
    "        pattern_regex = re.compile(pattern.regex, re.DOTALL)\n",
    "        match = pattern_regex.match(paragraph)\n",
    "        if match:\n",
    "            if pattern.multi_line == False:\n",
    "                return Heading(level=level, enumeration=match.group(1), heading_text=match.group(2))\n",
    "            else:\n",
    "                _, rest = split_paragraph(paragraph)\n",
    "                return Heading(level=level, enumeration=match.group(1), heading_text=rest)\n",
    "\n",
    "## Tests\n",
    "test_doc1 = \"Chapter VII: The Final Chapter\"\n",
    "test_pattern1 = HeadingPattern(level=Level.H1, regex=r'^Chapter ([IVXLC]+): (.+)$', multi_line=False)\n",
    "\n",
    "test_doc2 = \"\\n\\nChapter 7:\\nThe Final Chapter\"\n",
    "test_pattern2 = HeadingPattern(level=Level.H1, regex=r'^Chapter (\\d+):', multi_line=True)\n",
    "\n",
    "assert match_heading(test_doc1, {Level.H1: test_pattern1}) == \\\n",
    "    Heading(level=Level.H1, enumeration=\"VII\", heading_text=\"The Final Chapter\")\n",
    "\n",
    "assert match_heading(test_doc2, {Level.H1: test_pattern2}) == \\\n",
    "    Heading(level=Level.H1, enumeration=\"7\", heading_text=\"The Final Chapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateMachineParser:\n",
    "    def __init__(self, document_name: str, heading_patterns: dict[Level, HeadingPattern]):\n",
    "        self.document = []\n",
    "        self.heading_names = {Level.H0: document_name, Level.H1: None, Level.H2: None, Level.H3: None}\n",
    "        self.patterns = heading_patterns\n",
    "        self.state = Level.H0\n",
    "\n",
    "    def parse(self, text):\n",
    "        paragraphs = text.split('\\n\\n')\n",
    "\n",
    "        segment_headings = {Level.H0: self.heading_names[Level.H0]}\n",
    "        segment = Segment(level=Level.H0, headings=segment_headings, body=[]) # preamble\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "\n",
    "            match = match_heading(paragraph, self.patterns)\n",
    "\n",
    "            # no heading found, so add paragraph to the current segment\n",
    "            if not match:\n",
    "                segment.body.append(paragraph)\n",
    "                continue\n",
    "\n",
    "            # found a heading!\n",
    "            self.document.append(segment) # add the last segment to document\n",
    "\n",
    "            self.state = match.level\n",
    "            new_headings = segment.headings.copy()\n",
    "            new_headings[match.level] = match\n",
    "            for level in Level: # have to delete the headings at higher levels in case of skips later\n",
    "                if level.value in new_headings and level.value > match.level.value:\n",
    "                    del new_headings[level]\n",
    "            segment = Segment(level=self.state, headings=new_headings, body=[]) # start a new segment\n",
    "        return self.document\n",
    "    \n",
    "    def _str_segment(self, segment: Segment) -> str:\n",
    "        \n",
    "        heading = segment.headings[segment.level]\n",
    "        heading_str = f\"Heading {heading.level} {heading.enumeration}: {heading.heading_text}\" if heading else \"\"\n",
    "        return f\"{heading_str}\\n\\n{segment.body}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\\n\".join([self._str_segment(segment) for segment in self.document])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Code**] Heading patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def llm(prompt: str, system: str = \"\"):\n",
    "    chat_completion = openai_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, honey, the sky is blue because of something called Rayleigh scattering. So,\n",
      "like, when sunlight enters the Earth's atmosphere, it collides with all these\n",
      "gas molecules. The blue light waves are shorter and scatter more than the other\n",
      "colors, making the sky look blue to our eyes. It’s kind of like how we choose\n",
      "the perfect shade of blue for an outfit—it just stands out more! ✨\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "\n",
    "r = llm(\"Why is the sky blue?\", system=\"You are Cher from the movie Clueless.\")\n",
    "print(fill(r, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin\n",
    "\n",
    "marvin.settings.openai.chat.completions.model = 'gpt-4o'\n",
    "\n",
    "r = marvin.classify(\n",
    "    \"I could take it or leave it.\",\n",
    "    labels=[\"positive\", \"negative\", \"neutral\"],\n",
    ")\n",
    "\n",
    "assert r == \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@marvin.fn\n",
    "def infer_regex_llm(examples: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Return a regular expression for document headings matching the\n",
    "    provided examples. The regular expression should match the example and any similar\n",
    "    headings, and should not match unrelated text. Leading terms such as\n",
    "    \"Chapter\", \"Section\", \"Article\", \"Title\", etc. should be included verbatim \n",
    "    in the regular expression. Assume that numbers and letters in the pattern\n",
    "    can take on a normal range (e.g., if you see 1, 2, 3 as examples you should\n",
    "    allow other digits like 7 in the match). Trailing descriptive text, following\n",
    "    a number or letter pattern, will vary from heading to heading (although it\n",
    "    should still be included in the match if it is on the first line).\n",
    "    Assume that capitalization is consistent within the document. The regular\n",
    "    expression should be PCRE-compatible, and expressed as raw strings (e.g.,\n",
    "    r'^Title \\\\d+$'. The regular expression should match the beginning of a line\n",
    "    with '^' (multiline mode), and the end of a line with '$'. There should be no\n",
    "    newlines in the regular expressions (the examples will just be single lines).\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_line(s: str) -> str:\n",
    "    return s.split('\\n')[0]\n",
    "\n",
    "def infer_regex(examples: list[str]) -> str:\n",
    "    first_lines = [first_line(example) for example in examples]\n",
    "    return infer_regex_llm(first_lines)\n",
    "\n",
    "def is_multi_line(examples: list[str]) -> bool:\n",
    "    return any('\\n' in example.strip() for example in examples)\n",
    "\n",
    "def infer_heading_patterns(example_headings: dict[Level, list[str]]) -> dict[Level, HeadingPattern]:\n",
    "    \"\"\"Infer heading patterns from examples. Return a dictionary mapping levels to\n",
    "    HeadingPattern objects.\"\"\"    \n",
    "    return {k: HeadingPattern(level=k, regex=infer_regex(v), multi_line=is_multi_line(v))\n",
    "            for k, v in example_headings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_example_headings = {\n",
    "    Level.H1: [\"Title 1: General Provisions\\n\",\n",
    "              \"Title 2: City of New York\\n\",\n",
    "              \"Title 3: Elected officials\\n\",\n",
    "    ],\n",
    "    Level.H2: [\"Chapter 1: Powers and Rights of the Corporation; Emblems and Insignia\\n\",\n",
    "              \"Chapter 2: Boundaries of the City\\n\",\n",
    "              \"Chapter 4: Board of Estimate\\n\",\n",
    "     ],\n",
    "    Level.H3: [\"§ 2-101 Name; powers and rights of the corporation; seal.\\n\",\n",
    "              \"§ 2-202 Division into boroughs and boundaries thereof.\\n\",\n",
    "              \"§ 3-140 Office of labor standards.\\n\",\n",
    "      ],\n",
    "}\n",
    "\n",
    "chicago_example_headings = {\n",
    "    Level.H1: [\"TITLE 1\\nGENERAL PROVISION\\n\",\n",
    "              \"TITLE 2\\nCITY GOVERNMENT AND ADMINISTRATION\\n\",\n",
    "              \"TITLE 3\\nREVENUE AND FINANCE\\n\",\n",
    "    ],\n",
    "    Level.H2: [\"CHAPTER 1-4\\nCODE ADOPTION - ORGANIZATION\\n\",\n",
    "              \"CHAPTER 1-8\\nCITY SEAL AND FLAG\\n\",\n",
    "              \"CHAPTER 1-12\\nCITY EMBLEMS\\n\",\n",
    "     ],\n",
    "    Level.H3: [\"1-4-010 Municipal Code of Chicago adopted.\\n\",\n",
    "              \"2-1-020 Code to be kept up-to-date.\\n\",\n",
    "              \"3-4-030 Official copy on file.\\n\",\n",
    "      ],\n",
    "}\n",
    "\n",
    "losangeles_example_headings = {\n",
    "    Level.H1: [\"CHAPTER I\\nGENERAL PROVISIONS AND ZONING\\n\",\n",
    "              \"CHAPTER IV\\nPUBLIC WELFARE\",\n",
    "              \"CHAPTER VII\\nTRANSPORTATION\\n\",\n",
    "    ],\n",
    "    Level.H2: [\"ARTICLE 1\\nGENERAL PROVISIONS\\n\",\n",
    "              \"ARTICLE 4\\nPUBLIC BENEFIT PROJECTS\\n\",\n",
    "              \"ARTICLE 4.3\\nELDERCARE FACILITY UNIFIED PERMIT PROCESS\\n\",\n",
    "     ],\n",
    "    Level.H3: [\"SEC. 11.00. PROVISIONS APPLICABLE TO CODE.\\n\",\n",
    "              \"SEC. 11.01. DEFINITIONS AND INTERPRETATION.\\n\",\n",
    "              \"SEC. 14.4.1. PURPOSE.\\n\",\n",
    "      ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<Level.H1: 1>: HeadingPattern(level=<Level.H1: 1>, regex=\"r'^Title \\\\d+: .+$'\", multi_line=False), <Level.H2: 2>: HeadingPattern(level=<Level.H2: 2>, regex=\"r'^Chapter \\\\d+: .+$'\", multi_line=False), <Level.H3: 3>: HeadingPattern(level=<Level.H3: 3>, regex=\"r'^§ \\\\d+-\\\\d+ .+$'\", multi_line=False)}\n",
      "{<Level.H1: 1>: HeadingPattern(level=<Level.H1: 1>, regex=\"r'^TITLE \\\\d+$'\", multi_line=True), <Level.H2: 2>: HeadingPattern(level=<Level.H2: 2>, regex=\"r'^CHAPTER \\\\d+-\\\\d+$'\", multi_line=True), <Level.H3: 3>: HeadingPattern(level=<Level.H3: 3>, regex=\"r'^\\\\d+-\\\\d+-\\\\d+ .+$'\", multi_line=False)}\n",
      "{<Level.H1: 1>: HeadingPattern(level=<Level.H1: 1>, regex=\"r'^CHAPTER [IVXLCDM]+$'\", multi_line=True), <Level.H2: 2>: HeadingPattern(level=<Level.H2: 2>, regex=\"r'^ARTICLE \\\\d+(\\\\.\\\\d+)?$'\", multi_line=True), <Level.H3: 3>: HeadingPattern(level=<Level.H3: 3>, regex=\"r'^SEC\\\\. \\\\d+\\\\.\\\\d*(?:\\\\.\\\\d+)*\\\\..*$'\", multi_line=False)}\n"
     ]
    }
   ],
   "source": [
    "nyc_patterns = infer_heading_patterns(nyc_example_headings)\n",
    "print(nyc_patterns)\n",
    "chicago_patterns = infer_heading_patterns(chicago_example_headings)\n",
    "print(chicago_patterns)\n",
    "la_patterns = infer_heading_patterns(losangeles_example_headings)\n",
    "print(la_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Action**] Specify heading patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_headings = {\n",
    "    Level.H1: [\"TITLE 1\\nGENERAL PROVISION\\n\",\n",
    "              \"TITLE 2\\nCITY GOVERNMENT AND ADMINISTRATION\\n\",\n",
    "              \"TITLE 3\\nREVENUE AND FINANCE\\n\",\n",
    "    ],\n",
    "    Level.H2: [\"CHAPTER 1-4\\nCODE ADOPTION - ORGANIZATION\\n\",\n",
    "              \"CHAPTER 1-8\\nCITY SEAL AND FLAG\\n\",\n",
    "              \"CHAPTER 1-12\\nCITY EMBLEMS\\n\",\n",
    "     ],\n",
    "    Level.H3: [\"1-4-010 Municipal Code of Chicago adopted.\\n\",\n",
    "              \"2-1-020 Code to be kept up-to-date.\\n\",\n",
    "              \"3-4-030 Official copy on file.\\n\",\n",
    "      ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<Level.H1: 1>: HeadingPattern(level=<Level.H1: 1>, regex=\"r'^TITLE \\\\d+$'\", multi_line=True), <Level.H2: 2>: HeadingPattern(level=<Level.H2: 2>, regex=\"r'^CHAPTER \\\\d+-\\\\d+$'\", multi_line=True), <Level.H3: 3>: HeadingPattern(level=<Level.H3: 3>, regex=\"r'^\\\\d+-\\\\d+-\\\\d+ .+$'\", multi_line=False)}\n"
     ]
    }
   ],
   "source": [
    "chicago_mini_patterns = infer_heading_patterns(example_headings)\n",
    "print(chicago_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Code**] Ingest municipal code into database & create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Level.H1: 1>: 'Title', <Level.H2: 2>: 'Chapter', <Level.H3: 3>: 'Section'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@marvin.fn\n",
    "def infer_level_name(pattern: HeadingPattern) -> str:\n",
    "    \"\"\"Infer level names from the regular expressions in the patterns. For example,\n",
    "    if pattern.regex is r'^Title \\\\d+$', the level name would be 'Title'. The name\n",
    "    should be a string starting with a capital letter, followed by lowercase letters,\n",
    "    with no punctuation. If there is no clear name (e.g., if the pattern is\n",
    "    r'^\\\\d+\\\\-\\\\d+\\\\-\\\\d+'), return 'Section'.\n",
    "    \"\"\"\n",
    "\n",
    "# shouldn't be necessary, but the LLM ignores the instructions about letters\n",
    "def letters_only(s: str) -> str:\n",
    "    return ''.join(c for c in s if c.isalpha())\n",
    "\n",
    "def infer_level_names(patterns: dict[Level, HeadingPattern]) -> dict[Level, str]:\n",
    "    return {k: letters_only(infer_level_name(v)) for k, v in patterns.items()}\n",
    "\n",
    "infer_level_names(chicago_mini_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Jurisdiction:\n",
    "    name: str\n",
    "    patterns: dict[Level, HeadingPattern]\n",
    "    source_local: str = ''\n",
    "    source_url: str = ''\n",
    "    raw_text: str = ''\n",
    "    parser: StateMachineParser | None = None\n",
    "    document: list[Segment] = field(default_factory=list)\n",
    "    autoload: bool = True    \n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.autoload:\n",
    "            self.load()\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Loads the text of local code from file (source_local).\"\"\"\n",
    "        try:\n",
    "            with open(self.source_local, \"r\") as f:\n",
    "                self.raw_text = f.read()\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error reading {self.source_local}: {e}\")\n",
    "\n",
    "# FIXME move to Action section below\n",
    "chicago_mini = Jurisdiction(\n",
    "    name=\"Chicago Mini\",\n",
    "    patterns=chicago_mini_patterns,\n",
    "    source_local=\"../data/chicago-mini/code.txt\",\n",
    "    source_url=\"https://www.chicago.gov/city/en/depts/doit/supp_info/municipal_code.html\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_mini.parser = StateMachineParser(document_name=\"Chicago Mini Code\", heading_patterns=chicago_mini.patterns)\n",
    "chicago_mini.document = chicago_mini.parser.parse(chicago_mini.raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661150"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chicago_mini.raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import connect\n",
    "from muni.llm import create_embedding, summarize\n",
    "from muni.structure import Node\n",
    "\n",
    "RESET = False\n",
    "EMBEDDING_LENGTH = len(create_embedding(\"test\"))\n",
    "\n",
    "def connection():\n",
    "    return connect(\n",
    "        dbname=\"regrag\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "        autocommit=True\n",
    "    )\n",
    "\n",
    "with connection() as conn:\n",
    "    if RESET:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS muni_associations;\")\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS muni CASCADE;\")\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS muni_associations (\n",
    "                jurisdiction TEXT,\n",
    "                association TEXT,\n",
    "                left_id INTEGER,\n",
    "                right_id INTEGER\n",
    "            );\n",
    "            \"\"\")\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS muni (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                jurisdiction TEXT,\n",
    "                L1_ref TEXT, L1_heading TEXT,\n",
    "                L2_ref TEXT, L2_heading TEXT,\n",
    "                L3_ref TEXT, L3_heading TEXT,\n",
    "                L4_ref TEXT, L4_heading TEXT,\n",
    "                segment INTEGER,\n",
    "                text TEXT,\n",
    "                embedding VECTOR(%s)\n",
    "            );\n",
    "            \"\"\", (EMBEDDING_LENGTH,))\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            ALTER TABLE muni\n",
    "                ADD COLUMN IF NOT EXISTS textsearchable tsvector\n",
    "                    GENERATED ALWAYS AS\n",
    "                    (to_tsvector('english',\n",
    "                        coalesce(jurisdiction, '') || ' ' ||\n",
    "                        coalesce(L1_heading, '') || ' ' ||\n",
    "                        coalesce(L2_heading, '') || ' ' ||\n",
    "                        coalesce(L3_heading, '') || ' ' ||\n",
    "                        coalesce(L4_heading, '') || ' ' ||\n",
    "                        coalesce(text, '') || ' '))\n",
    "                    STORED;\n",
    "            \"\"\"\n",
    "        )\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            DROP INDEX IF EXISTS muni_fulltext;\n",
    "            CREATE INDEX muni_fulltext ON muni USING GIN (textsearchable);\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "def node_embedding(node: Node) -> list[float]:\n",
    "    pre = '\\n'.join(list(node.metadata['headings'].values()))\n",
    "    summary = summarize(node.text)\n",
    "    if summary is not None:\n",
    "        embedding_text = pre + summary\n",
    "    else:\n",
    "        embedding_text = pre\n",
    "    return create_embedding(embedding_text)\n",
    "\n",
    "def upload(node: Node) -> None:\n",
    "    if node.text:\n",
    "        references = node.metadata['references']\n",
    "        headings = node.metadata['headings']\n",
    "        with connection() as conn:\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO muni (\n",
    "                        jurisdiction,\n",
    "                        L1_ref, L1_heading,\n",
    "                        L2_ref, L2_heading,\n",
    "                        L3_ref, L3_heading,\n",
    "                        L4_ref, L4_heading,\n",
    "                        segment,\n",
    "                        text,\n",
    "                        embedding\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "                    \"\"\",\n",
    "                    (\n",
    "                        \"Chicago\",\n",
    "                        references.get(\"title\", \"\"),   headings.get(\"title\", \"\"),   # L1\n",
    "                        references.get(\"chapter\", \"\"), headings.get(\"chapter\", \"\"), # L2\n",
    "                        references.get(\"article\", \"\"), headings.get(\"article\", \"\"), # L3\n",
    "                        references.get(\"section\", \"\"), headings.get(\"section\", \"\"), # L3\n",
    "                        0, # can add break-down segments later for large text blocks\n",
    "                        node.text,\n",
    "                        node_embedding(node),\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    if not node.children:\n",
    "        return\n",
    "    for child in node.children:\n",
    "        upload(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Action**] Upload municipal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago = Jurisdiction(\n",
    "    name=\"Chicago\",\n",
    "    hierarchy={\n",
    "        \"title\":   r\"TITLE \\d+\",\n",
    "        \"chapter\": r\"CHAPTER \\d+-\\d+\",\n",
    "        \"article\": r\"ARTICLE [IVX]+\\\\.\",\n",
    "        \"section\": r\"\\d+-\\d+-\\d+\",\n",
    "    },\n",
    "    source_local=\"../data/chicago/chicago.txt\",\n",
    "    source_url=\"https://www.chicago.gov/city/en/sites/covid-19/home.html\",\n",
    ")\n",
    "chicago_tree = chicago.parse()\n",
    "\n",
    "upload(chicago_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Code**] Find associations among sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through rows in the muni database and identify definitions\n",
    "\n",
    "from muni.llm import definition, analyze_context\n",
    "\n",
    "sql_select = \"\"\"\n",
    "    SELECT  id,\n",
    "        L1_ref, L1_heading,\n",
    "        L2_ref, L2_heading,\n",
    "        L3_ref, L3_heading,\n",
    "        L4_ref, L4_heading,\n",
    "        text\n",
    "    FROM muni;\n",
    "    \"\"\"\n",
    "\n",
    "sql_unique = \"\"\"\n",
    "    BEGIN\n",
    "        IF NOT EXISTS (\n",
    "            SELECT FROM pg_constraint\n",
    "            WHERE conname = 'unique_associations')\n",
    "            AND   conrelid = 'muni_associations'::regclass\n",
    "        ) \n",
    "        THEN\n",
    "            ALTER TABLE muni_associations\n",
    "            ADD CONSTRAINT unique_associations UNIQUE (jurisdiction, association, left_id, right_id);\n",
    "        END IF;\n",
    "    END;\n",
    "    \"\"\"\n",
    "\n",
    "sql_assoc = \"\"\"\n",
    "    INSERT INTO muni_associations (jurisdiction, association, left_id, right_id)\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "    ON CONFLICT (jurisdiction, association, left_id, right_id) DO NOTHING;\n",
    "    \"\"\"\n",
    "\n",
    "def scope_map(scope):\n",
    "    \"\"\"For a given scope, what are the columns in muni that need to match?\"\"\"\n",
    "    table = {'global': ['jurisdiction'],\n",
    "             'title': ['jurisdiction', 'L1_ref'],\n",
    "             'chapter': ['jurisdiction', 'L1_ref', 'L2_ref'],\n",
    "             'article': ['jurisdiction', 'L1_ref', 'L2_ref', 'L3_ref'],\n",
    "             'section': ['jurisdiction', 'L1_ref', 'L2_ref', 'L3_ref', 'L4_ref']\n",
    "             }\n",
    "    if scope not in table.keys():\n",
    "        return None\n",
    "    return table[scope]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_associations(conn, id_, scope, context_type):\n",
    "    \"\"\"Set associations with a row in muni with all rows matching the scope.\n",
    "    Args:\n",
    "        conn: a connection to the database\n",
    "        id_: the id of the row to associate\n",
    "        scope: the scope of the association (e.g. 'title', 'chapter', 'article', 'section')\n",
    "        context_type: the type of association (e.g. 'definition')\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cursor:\n",
    "        # get the jurisdiction and the references\n",
    "        cursor.execute(f\"SELECT jurisdiction, L1_ref, L2_ref, L3_ref, L4_ref FROM muni WHERE id = {id_}\")\n",
    "        jurisdiction, L1_ref, L2_ref, L3_ref, L4_ref = cursor.fetchone()\n",
    "        # get the columns that need to match\n",
    "        columns = scope_map(scope)\n",
    "        if not columns:\n",
    "            return\n",
    "        # get the rows that match the scope\n",
    "        match_str = ' AND '.join([f\"{col} = '{val}'\" for col, val in zip(columns, [jurisdiction, L1_ref, L2_ref, L3_ref, L4_ref])])\n",
    "        cursor.execute(f\"SELECT id FROM muni WHERE {match_str} AND id != {id_}\")\n",
    "        rows = cursor.fetchall()\n",
    "        # set the associations\n",
    "        for row in rows:\n",
    "            cursor.execute(sql_assoc, (jurisdiction, context_type, id_, row[0]))\n",
    "\n",
    "def find_associations(conn):\n",
    "    allowed_types = ['penalty', 'definition', 'interpretation', 'date']\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(sql_select)\n",
    "        rows = cursor.fetchall()\n",
    "        for row in rows:\n",
    "            id_, L1_ref, L1_heading, L2_ref, L2_heading, L3_ref, L3_heading, L4_ref, L4_heading, text = row\n",
    "            headings = {'title': L1_heading, 'chapter': L2_heading, 'article': L3_heading, 'section': L4_heading}\n",
    "            r = analyze_context(text, headings, model='gpt-4')\n",
    "            if r:\n",
    "                context_type, scope = r\n",
    "                if context_type in allowed_types:\n",
    "                    print(f\"* Setting associations for id {id_}\")\n",
    "                    print(f\"  Context type: {context_type}; Scope: {scope}\")\n",
    "                    print(\"  --> %s ...\" % text[:80].replace('\\n', ' '))\n",
    "                    set_associations(conn, id_, scope, context_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Code**] Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_semantic_query(conn, query, limit=10):\n",
    "    query_embedding = create_embedding(query)\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = \"\"\"\n",
    "        SELECT id, L4_heading, text\n",
    "        FROM muni\n",
    "        WHERE jurisdiction = 'Chicago'\n",
    "        ORDER BY embedding <=> %s\n",
    "        LIMIT %s;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql, (str(query_embedding), limit))\n",
    "        return cursor.fetchall()\n",
    "        \n",
    "#with connection() as conn:        \n",
    "#    results = simple_semantic_query(conn, 'drug paraphernalia')\n",
    "#for r in results:\n",
    "#    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_full_text_query(conn, query, limit=10):\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = \"\"\"\n",
    "        WITH tsq AS (\n",
    "            SELECT to_tsquery('english', %s) AS search\n",
    "            )\n",
    "        SELECT id, L4_heading, text\n",
    "        FROM muni, tsq\n",
    "        WHERE jurisdiction = 'Chicago'\n",
    "        AND textsearchable @@ tsq.search\n",
    "        ORDER BY ts_rank_cd(textsearchable, tsq.search)\n",
    "        LIMIT %s;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql, (query, limit))\n",
    "        return cursor.fetchall()\n",
    "\n",
    "#with connection() as conn:        \n",
    "#    results = simple_full_text_query(conn, 'drug & paraphernalia')\n",
    "#for r in results:\n",
    "#     print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do a more complicated hybrid search, borrowing and adapting from \n",
    "# https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search_rrf.py\n",
    "\n",
    "def hybrid_query(conn, query, limit=10):\n",
    "    embedding = create_embedding(query)\n",
    "\n",
    "    sql = \"\"\"\n",
    "    WITH semantic_search AS (\n",
    "        SELECT id, L4_heading, RANK () OVER (ORDER BY embedding <=> %(embedding)s) AS rank\n",
    "        FROM muni\n",
    "        ORDER BY embedding <=> %(embedding)s\n",
    "        LIMIT 20\n",
    "    ),\n",
    "    keyword_search AS (\n",
    "        SELECT id, L4_heading, RANK () OVER (ORDER BY ts_rank_cd(textsearchable, query) DESC)\n",
    "        FROM muni, plainto_tsquery('english', %(query)s) query\n",
    "        WHERE textsearchable @@ query\n",
    "        ORDER BY ts_rank_cd(textsearchable, query) DESC\n",
    "        LIMIT 20\n",
    "    )\n",
    "    SELECT\n",
    "        COALESCE(semantic_search.id, keyword_search.id) AS id,\n",
    "        COALESCE(1.0 / (%(k)s + semantic_search.rank), 0.0) +\n",
    "        COALESCE(1.0 / (%(k)s + keyword_search.rank), 0.0) AS score,\n",
    "        COALESCE(semantic_search.L4_heading, keyword_search.L4_heading) AS L4_heading\n",
    "    FROM semantic_search\n",
    "    FULL OUTER JOIN keyword_search ON semantic_search.id = keyword_search.id\n",
    "    ORDER BY score DESC\n",
    "    LIMIT %(limit)s;\n",
    "    \"\"\"\n",
    "    result = conn.execute(sql, {'query': query, 'embedding': str(embedding), 'limit': limit, 'k': 60})\n",
    "    return result.fetchall()\n",
    "\n",
    "#with connection() as conn:\n",
    "#    results = hybrid_query(conn, 'drug paraphernalia')\n",
    "\n",
    "#for row in results:\n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try query augmentation using Hyde (generation of synthetic replies matching the\n",
    "# format of expected answers)\n",
    "from muni.llm import augmented_embedding\n",
    "\n",
    "def augmented_query(conn, query, limit=10):\n",
    "    query_embedding = augmented_embedding(query, orig_weight = 0.5)\n",
    "    with conn.cursor() as cursor:\n",
    "        sql = \"\"\"\n",
    "        SELECT id, L4_heading, text\n",
    "        FROM muni\n",
    "        WHERE jurisdiction = 'Chicago'\n",
    "        ORDER BY embedding <=> %s\n",
    "        LIMIT %s;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql, (str(query_embedding), limit))\n",
    "        return cursor.fetchall()\n",
    "        \n",
    "#with connection() as conn:        \n",
    "#    results = augmented_query(conn, 'Does the code restrict drug paraphernalia')\n",
    "#for r in results:\n",
    "#    print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
